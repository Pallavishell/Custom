{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e60cae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1,\"a\",30),(2,\"b\",32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3824f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0587ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "userschema = StructType([StructField(\"id\",IntegerType()),\n",
    "                         StructField(\"name\",StringType()),\n",
    "                         StructField(\"age\",IntegerType())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "decaeb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "752a8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f1fe0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/22 04:23:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd7ccfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data,userschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e4b9dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "| id|name|age|\n",
      "+---+----+---+\n",
      "|  1|   a| 30|\n",
      "|  2|   b| 32|\n",
      "+---+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "931afe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [\n",
    "    (1, \"Alice\", [\"Reading\", \"Hiking\"]),\n",
    "    (2, \"Bob\", [\"Swimming\", \"Gardening\", \"Painting\"]),\n",
    "    (3, \"Charlie\", [\"Cooking\"]),\n",
    "    (4, \"David\", [\"Photography\", \"Skiing\", \"Cooking\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e9490d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "userschema2 = StructType([StructField(\"id\",IntegerType()),\n",
    "                         StructField(\"name\",StringType()),\n",
    "                         StructField(\"hobby\",ArrayType(StringType()))\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1b6f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame(data2,userschema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6ebfdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+\n",
      "| id|   name|               hobby|\n",
      "+---+-------+--------------------+\n",
      "|  1|  Alice|   [Reading, Hiking]|\n",
      "|  2|    Bob|[Swimming, Garden...|\n",
      "|  3|Charlie|           [Cooking]|\n",
      "|  4|  David|[Photography, Ski...|\n",
      "+---+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86f652e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77dd549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------+\n",
      "| id|   name|        col|\n",
      "+---+-------+-----------+\n",
      "|  1|  Alice|    Reading|\n",
      "|  1|  Alice|     Hiking|\n",
      "|  2|    Bob|   Swimming|\n",
      "|  2|    Bob|  Gardening|\n",
      "|  2|    Bob|   Painting|\n",
      "|  3|Charlie|    Cooking|\n",
      "|  4|  David|Photography|\n",
      "|  4|  David|     Skiing|\n",
      "|  4|  David|    Cooking|\n",
      "+---+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"id\",\"name\",explode(\"Hobby\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bda4d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+\n",
      "| id|   name|               hobby|   newhobby|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  1|  Alice|   [Reading, Hiking]|    Reading|\n",
      "|  1|  Alice|   [Reading, Hiking]|     Hiking|\n",
      "|  2|    Bob|[Swimming, Garden...|   Swimming|\n",
      "|  2|    Bob|[Swimming, Garden...|  Gardening|\n",
      "|  2|    Bob|[Swimming, Garden...|   Painting|\n",
      "|  3|Charlie|           [Cooking]|    Cooking|\n",
      "|  4|  David|[Photography, Ski...|Photography|\n",
      "|  4|  David|[Photography, Ski...|     Skiing|\n",
      "|  4|  David|[Photography, Ski...|    Cooking|\n",
      "+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.withColumn(\"newhobby\",explode(\"Hobby\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09b67588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------+\n",
      "| id|   name|      Hobby|\n",
      "+---+-------+-----------+\n",
      "|  1|  Alice|    Reading|\n",
      "|  1|  Alice|     Hiking|\n",
      "|  2|    Bob|   Swimming|\n",
      "|  2|    Bob|  Gardening|\n",
      "|  2|    Bob|   Painting|\n",
      "|  3|Charlie|    Cooking|\n",
      "|  4|  David|Photography|\n",
      "|  4|  David|     Skiing|\n",
      "|  4|  David|    Cooking|\n",
      "+---+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.withColumn(\"Hobby\",explode(\"Hobby\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc503dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with columns adds a new column or replaces it if same name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "affc4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2\\\n",
    ".withColumn(\"Hobby\",explode(\"Hobby\"))\\\n",
    ".withColumn(\"ingestion_date\",current_timestamp())#try truncate=True ans see what happens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
